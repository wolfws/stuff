{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python 3\n",
    "import urllib.request\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import pickle\n",
    "import warnings\n",
    "import urllib.parse\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from bs4 import BeautifulSoup \n",
    "from bing_web_search_api import Client\n",
    "batch_type = \"xyzbatch\" # a batch could be a code search word or a multi-level website / directory that your \n",
    "# search engine wants to index, i.e. a directory of gaming sub-websites\n",
    "apikey = 'your Bing API key here'\n",
    "exceptions = []\n",
    "\n",
    "\"\"\"\n",
    "# This is an unofficial Microsoft Bing api V.5 search/indexing engine bot demo code. \n",
    "# This sample code demonstrates how to (a) get results from Bing API (for which you need a valid license) and \n",
    "# (b) navigate to the website urls to extract indexing information for your custom search engine\n",
    "# Sample use: build a custom search engine that indexes websites / blogs dedicated to sports cars collectors.\n",
    "# Your search engine must comply with websites' TOS and robots policy.\n",
    "\"\"\"\n",
    "\n",
    "crms = {\"xyzbatch\":{\n",
    "        \"crm_base\": \"http://xyzbatch\",\n",
    "        \"crm_email_base\": \"xyzbatch\"\n",
    "    }}\n",
    "\n",
    "class SiteIndexer(object):\n",
    "    def __init__(self):\n",
    "        # source: https://gist.github.com/dideler/5219706\n",
    "        self.regex = re.compile((\"([a-z0-9!#$%&'*+\\/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+\\/=?^_`\"\n",
    "                    \"{|}~-]+)*(@|\\sat\\s)(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?(\\.|\"\n",
    "                    \"\\sdot\\s))+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?)\"))\n",
    "        self.head = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "                                                              Chrome/44.0.2403.155 Safari/537.36'\n",
    "\n",
    "    def getEmails(self, textStr):\n",
    "        return (email[0] for email in re.findall(self.regex, textStr) if not email[0].startswith('//'))\n",
    "\n",
    "    def getImgString(self, url):\n",
    "        req = urllib.request.Request(url, data=None, headers={'User-Agent': self.head})\n",
    "        htmlfile = urllib.request.urlopen(req)\n",
    "        htmltext = htmlfile.read()\n",
    "        return base64.b64encode(htmltext)\n",
    "\n",
    "    def readHTML(self,url):\n",
    "        req = urllib.request.Request(url, data=None, headers={'User-Agent': self.head})\n",
    "        htmlfile = urllib.request.urlopen(req)\n",
    "        return htmlfile.read()\n",
    "    \n",
    "    def getSearchResults(self, query):\n",
    "        # https://github.com/h-kanazawa/bing-web-search-api/blob/master/bing_web_search_api/client.py\n",
    "        # https://msdn.microsoft.com/en-us/library/dn760794.aspx\n",
    "        client = Client(apikey=apikey)\n",
    "        response, content = client.search(count=50,q=query)\n",
    "        search_results = json.loads(content.decode('utf-8')).get(\"webPages\")\n",
    "        sites = []\n",
    "        for i in range(len(search_results[\"value\"])):\n",
    "            url = urllib.parse.urlparse(search_results.get(\"value\")[i].get(\"displayUrl\"), 'https').geturl()\n",
    "            sites.append(url)\n",
    "        return sites\n",
    "    \n",
    "    def getIndexedWebsites(self,sites):\n",
    "        urls = {}\n",
    "        for url in sites:\n",
    "            try:\n",
    "                if not \"xyzbatch\".lower() in url.lower():\n",
    "                    exceptions.append(url)\n",
    "                    continue\n",
    "                crm_base = crms[batch_type].get(\"crm_base\")\n",
    "                crm_email_base = crms[batch_type].get(\"crm_email_base\")\n",
    "                if \"http\" not in url: url= crm_base + url\n",
    "                htmltext = extractor.readHTML(url)\n",
    "                soup = BeautifulSoup(htmltext)\n",
    "                logo = extractor.getImgString(soup.find(\"img\", {\"id\": \"xyzbatch\"}).get('src'))\n",
    "                urls[url] = {}\n",
    "                urls[url].update({\"logo\":logo})\n",
    "                aurl  = soup.find_all(\"a\", limit=250)\n",
    "                for i, a in enumerate(aurl):\n",
    "                    urls[url][i] = {}\n",
    "                    href = a.get('href')\n",
    "                    url_text = a.string.replace(\"\\r\\n\",\"\").strip() if not a.string is None else \"\"\n",
    "                    if href is not None and len(href) > 0 and \"mailto:\" in href: \n",
    "                        urls[url][i].update({\"email\": href.replace(\"mailto:\",\"\")})  \n",
    "                    elif href is not None and len(href) > 0 and \"tel:\" in href:\n",
    "                        urls[url][i].update({\"phone\": href.replace(\"tel:\",\"\")})  \n",
    "                    elif href is not None and len(href) > 0:\n",
    "                        if \"http\" not in href: href= crm_base + href\n",
    "                        urls[url][i].update({\"url\": href, \"urltext\":url_text})  \n",
    "                        if \"contacts\" in url_text.lower():\n",
    "                            htmltext = extractor.readHTML(href)\n",
    "                            emails = [a for a in list(extractor.getEmails(str(htmltext))) if crm_email_base not in a]\n",
    "                            urls[url][i].update({\"contact_email\": emails}) \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                exceptions.append(url)\n",
    "        return urls\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"your search query\" #  Use combinatoric function itertools to generate a list of all possible search combinations\n",
    "    # of target attributes, i.e. a collection of tuples in the shape of (attribute 1, attribute 2, attribute X)\n",
    "    extractor = SiteIndexer()\n",
    "    sites = extractor.getSearchResults(query) # Bing API v.5 # you can also limit results to the latest search data per Bing api specs\n",
    "    #pickle.dump(sites, open( \"sites.pkl\", \"wb\" ) )\n",
    "    #sites = pickle.load( open( \"sites.pkl\", \"rb\" ) )\n",
    "    urls = extractor.getIndexedWebsites(sites) # Index Bing results by visiting the individual urls\n",
    "    #print(\"exceptions\",exceptions)\n",
    "    print(\"done\")    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
